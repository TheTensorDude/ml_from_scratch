{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39a9680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31e3fe38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is pytorch connected to GPU?\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "618085b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# If you have cuda it will run on cuda else cpu.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "386c4579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# what is the name of the gpu?\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "print(gpu_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2454e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [4, 5, 6, 7]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor manually!\n",
    "list_tensor = [[1, 2, 3, 4], [4, 5, 6, 7]]\n",
    "tensor = torch.tensor(list_tensor)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2bbba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [4., 5., 6., 7.]])\n"
     ]
    }
   ],
   "source": [
    "# How do we specify the type?\n",
    "list_tensor = [[1, 2, 3, 4], [4, 5, 6, 7]]\n",
    "tensor = torch.tensor(list_tensor, \n",
    "                      dtype = torch.float32)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8da0777c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [4., 5., 6., 7.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# How do we put it in GPU?\n",
    "list_tensor = [[1, 2, 3, 4], [4, 5, 6, 7]]\n",
    "tensor = torch.tensor(list_tensor, \n",
    "                      dtype = torch.float32,\n",
    "                      device = \"cuda\")\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16ad05df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [4., 5., 6., 7.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# What if we do not need gradient?\n",
    "# How do we put it in GPU?\n",
    "list_tensor = [[1, 2, 3, 4], [4, 5, 6, 7]]\n",
    "tensor = torch.tensor(list_tensor, \n",
    "                      dtype = torch.float32,\n",
    "                      device = \"cuda\",\n",
    "                      requires_grad = False)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b444607c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: torch.float32\n",
      "Device: cuda:0\n",
      "Shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# how do you know the dtype?\n",
    "print(\"Data type:\", tensor.dtype)\n",
    "\n",
    "# to know the device\n",
    "print(\"Device:\", tensor.device)\n",
    "\n",
    "# How do you know the shape?\n",
    "print(\"Shape:\", tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df17c49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4013e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9256e+10, 3.0892e-41],\n",
      "        [4.3458e+09, 3.0890e-41, 5.4482e+14, 4.5623e-41, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Uninitialized data. Whatever is in the memory is filled inside the tensor.\n",
    "uninit_tensor = torch.empty(size = (5, 5))\n",
    "print(uninit_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46c2c57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor filled with zeros\n",
    "zeros_tensor = torch.zeros(size = (3, 3))\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "397bb22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor filled with ones\n",
    "zeros_tensor = torch.ones(size = (3, 3))\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4bb466fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5315, 0.9200, 0.7290],\n",
      "        [0.2167, 0.9279, 0.1685],\n",
      "        [0.1136, 0.6284, 0.1838]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize randomly using uniform dist\n",
    "tensor = torch.rand(size = (3, 3))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f80a251b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Identity matrix\n",
    "identity_tensor = torch.eye(n = 3, m = 3)\n",
    "print(identity_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "702c4b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Similar to list(range(start, end, step)) in python\n",
    "ranges = torch.arange(start = 0, end = 5, step = 1)\n",
    "print(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3282dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Creates range of steps(10) number of bins\n",
    "x = torch.linspace(start = 0.1, end = 1, steps = 10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e40c5b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# if we want to preseve the values across the diagonal then we can\n",
    "# pass the tensor\n",
    "tensor = torch.diag(torch.ones(5))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46a92332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "# INT16 tensor\n",
    "print(tensor.short())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "69ffa92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "# INT64 tensor\n",
    "print(tensor.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd41d35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# FLOAT16\n",
    "print(tensor.half())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "763d0e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# FLOAT64\n",
    "print(tensor.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37ee358d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Work with numpy \n",
    "import numpy as np\n",
    "\n",
    "# numpy array\n",
    "numpy_tensor = np.zeros((5 , 5))\n",
    "\n",
    "# convert numpy array to torch.tensor\n",
    "tensor = torch.from_numpy(numpy_tensor)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b059be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Bacis Linear algebra OPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0bdfc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product using python list\n",
    "def dot_product(a, b):\n",
    "    return sum([aval * bval for aval, bval in zip(a, b)])\n",
    "\n",
    "\n",
    "# Matrix multiplication in using python list\n",
    "def matmul(a, b):\n",
    "    # resultant matrix\n",
    "    res = []\n",
    "    # Looping through the rows of a\n",
    "    for i in range(len(a)):\n",
    "        # appending one row to the resultant matrix\n",
    "        res.append([])\n",
    "        # looping through the rows of b\n",
    "        for j in range(len(b)):\n",
    "            # Performing element wise sum, also called dot product\n",
    "            element_wise_sum = dot_product(a[i], b[j])\n",
    "            # appending to row \"i\" of the resultant matrix\n",
    "            res[i].append(element_wise_sum)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd66a5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[50, 68], [122, 167]]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "]\n",
    "\n",
    "b = [\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "]\n",
    "\n",
    "matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d25aac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Distance from origin\n",
    "def distance_from_origin(w):\n",
    "    return sqrt(sum([wval ** 2 for wval in w]))\n",
    "\n",
    "a = [1, 2, 3]\n",
    "distance_from_origin(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "81749fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.196152422706632"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distance between two vectors\n",
    "def distance_between_two_vectors(a, b):\n",
    "    return sqrt(sum([(aval - bval) ** 2 for aval, bval in zip(a, b)]))\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "distance_between_two_vectors(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dbbb399f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n",
      "tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "# vector addition using torch\n",
    "# can be used for residual connections.\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "absum = torch.add(a, b)\n",
    "print(absum)\n",
    "\n",
    "# More pythonic!\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "420a2a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2500, 0.4000, 0.5000])\n",
      "tensor([0.5000, 1.0000, 1.5000])\n"
     ]
    }
   ],
   "source": [
    "# division\n",
    "div = torch.true_divide(a, b)\n",
    "print(div)\n",
    "\n",
    "# Divides each element by 2\n",
    "div = torch.true_divide(a, 2)\n",
    "print(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4a76ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[0.4984, 0.5983, 0.5536, 0.4711, 0.0625],\n",
      "        [0.8188, 0.6412, 0.2827, 0.9892, 0.3091],\n",
      "        [0.6976, 0.1063, 0.3415, 0.5130, 0.2362],\n",
      "        [0.1838, 0.1359, 0.6560, 0.4277, 0.1255],\n",
      "        [0.0595, 0.0527, 0.8090, 0.2089, 0.2726]])\n",
      "b: tensor([[0.3735, 0.9051, 0.5762, 0.2842, 0.2377]])\n",
      "B is brodcasted along the first axis.\n",
      "tensor([[ 0.1250, -0.3068, -0.0226,  0.1869, -0.1751],\n",
      "        [ 0.4453, -0.2640, -0.2934,  0.7050,  0.0714],\n",
      "        [ 0.3242, -0.7988, -0.2347,  0.2288, -0.0015],\n",
      "        [-0.1897, -0.7692,  0.0798,  0.1436, -0.1122],\n",
      "        [-0.3140, -0.8524,  0.2329, -0.0752,  0.0349]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting | IMPORTANT!\n",
    "a = torch.rand(size = (5, 5))\n",
    "b = torch.rand(size = (1, 5))\n",
    "\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)\n",
    "\n",
    "print(\"B is brodcasted along the first axis.\")\n",
    "z = a - b\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "faabf455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a: torch.Size([4, 5])\n",
      "Sum across the first dimension: tensor([2.9384, 3.3499, 1.9201, 2.6919])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(size = (4, 5))\n",
    "print(\"Shape of a:\", a.shape)\n",
    "print(\"Sum across the first dimension:\", torch.sum(a, dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7dd3e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9641, 0.1176, 0.8918, 0.1839, 0.7810],\n",
      "        [0.7747, 0.7300, 0.6658, 0.5261, 0.6532],\n",
      "        [0.2188, 0.2446, 0.0414, 0.4322, 0.9830],\n",
      "        [0.5028, 0.8465, 0.2300, 0.7743, 0.3383]])\n",
      "tensor([[0.1176, 0.1839, 0.7810, 0.8918, 0.9641],\n",
      "        [0.5261, 0.6532, 0.6658, 0.7300, 0.7747],\n",
      "        [0.0414, 0.2188, 0.2446, 0.4322, 0.9830],\n",
      "        [0.2300, 0.3383, 0.5028, 0.7743, 0.8465]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "vals, indices = torch.sort(a)\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f35231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values that are less then min will be set to min\n",
    "# vals that are greater than max will be clamped to max\n",
    "torch.clamp(a, min = 2, max = 10)\n",
    "\n",
    "# We can create relu using clamp\n",
    "def relu(x):\n",
    "    return torch.clamp(x, min = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffeb6d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 0, 0, 1, 1, 1])\n",
    "\n",
    "# check if any of the value is True\n",
    "print(torch.any(a))\n",
    "\n",
    "# check if all is True\n",
    "print(torch.all(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc2ee0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([5, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([5])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# indexing\n",
    "batch_size, features = 5, 512\n",
    "data = torch.rand(size = (batch_size, features))\n",
    "\n",
    "print(\"Shape:\", data.shape)\n",
    "\n",
    "# Retriving the first example data point in the batch\n",
    "print(data[0, :].shape)\n",
    "\n",
    "# Retriving the first feature of all examples\n",
    "print(data[:, 0].shape) # we have 5 examples\n",
    "\n",
    "# 3rd example, first 10 features\n",
    "print(data[2, 0 : 10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7091844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([2, 5, 8])\n",
      "Tensor: tensor([[0.1901, 0.7005, 0.5319, 0.7154, 0.1544],\n",
      "        [0.5504, 0.7524, 0.3400, 0.0268, 0.0097],\n",
      "        [0.8642, 0.5110, 0.6382, 0.0090, 0.2280]])\n",
      "tensor([0.7005, 0.3400])\n"
     ]
    }
   ],
   "source": [
    "# Something more fancy!\n",
    "x = torch.arange(10)\n",
    "print(x)\n",
    "\n",
    "# it will pick up the 3rd, 6th and 9th example in the batch\n",
    "indices = [2, 5, 8]\n",
    "print(x[indices])\n",
    "\n",
    "\n",
    "# Picking up rows and columns based on indices\n",
    "x = torch.rand(size = (3, 5))\n",
    "print(\"Tensor:\", x)\n",
    "\n",
    "# pick up the element at first row and second column\n",
    "# and element at second row and third column\n",
    "rows, cols = [0, 1], [1, 2]\n",
    "print(x[rows, cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b64f2fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1850, 0.2250, 0.0531, 0.7598, 0.8948],\n",
      "        [0.1100, 0.1997, 0.2250, 0.6599, 0.0367],\n",
      "        [0.4100, 0.9262, 0.0754, 0.2047, 0.3536]])\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size = (3, 5))\n",
    "print(x)\n",
    "\n",
    "# pick up all elements less than 0.50 or greater than 0.55\n",
    "x[(x < 0.50) | (x > 0.55)]\n",
    "\n",
    "# All even numbers\n",
    "x = torch.arange(10)\n",
    "print(x[x.remainder(2) == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "13fd3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0,   0, 121, 144, 169, 196, 225, 256, 289])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT!\n",
    "condition = x >10\n",
    "if_condition = x ** 2\n",
    "else_condition = 0\n",
    "\n",
    "x = torch.arange(6, 18)\n",
    "\n",
    "print(torch.where(condition, if_condition, else_condition))\n",
    "\n",
    "# All the unique values\n",
    "x.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76194611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size = (2, 2))\n",
    "\n",
    "# how many dimensions do we have?\n",
    "print(x.ndimension())\n",
    "\n",
    "# Numbe of elements in x\n",
    "print(x.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "13da44ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# RESHAPING A TENSOR!\n",
    "x = torch.arange(9)\n",
    "print(x)\n",
    "\n",
    "# Make it 3 x 3, using view\n",
    "# Performs reshaping in place | Superior than view but memory should be contigious.\n",
    "print(x.view(3, 3))\n",
    "\n",
    "# using reshape\n",
    "print(x.reshape(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a5c45abf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-ce25cba264a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "x = torch.empty((3, 3)).T\n",
    "x.view(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9885f399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6539e-09, 1.5917e-05, 0.0000e+00, 3.0885e-41, 0.0000e+00, 1.4257e+00,\n",
       "        0.0000e+00, 4.7684e-06, 1.1210e-43])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to make anything contigious?\n",
    "x.contiguous()\n",
    "\n",
    "\n",
    "# Make it contigious first and then perform view!\n",
    "x.contiguous().view(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ee91a268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5831, 0.2233, 0.4322, 0.0102, 0.9558],\n",
      "         [0.8117, 0.6465, 0.2381, 0.6944, 0.6036]]])\n",
      "tensor([0.5831, 0.2233, 0.4322, 0.0102, 0.9558, 0.8117, 0.6465, 0.2381, 0.6944,\n",
      "        0.6036])\n"
     ]
    }
   ],
   "source": [
    "# How to flatten?\n",
    "x = torch.rand(1, 2, 5)\n",
    "print(x)\n",
    "\n",
    "# Flattening!\n",
    "print(x.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "31d9d98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5, 2])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This can be pretty useful for implementing multihead attention!\n",
    "# We can permute the dimension for the heads.\n",
    "# Switch the axis!\n",
    "x = torch.rand(64, 2, 5)\n",
    "\n",
    "# we want to switch the axis!\n",
    "x.permute(0, 2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4599ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x.unsqueeze(0).shape)\n",
    "print(x.unsqueeze(1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
